{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/danadria/Skills-Lab-Introduction-to-Transformers-BERT-and-Explainable-NLP/blob/main/skills_lab_sentiment_analysis_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8ViQ1tgzpeg"
   },
   "source": [
    "# Practical 10: Transformers for Sentiment Analysis\n",
    "#### Daniel Anadria\n",
    "\n",
    "<img src=\"img/uu_logo.png\" alt=\"logo\" align=\"right\" title=\"UU\" width=\"50\" height=\"20\" />\n",
    "\n",
    "\n",
    "#### Applied Text Mining - Utrecht Summer School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c6SamrvMSsH"
   },
   "source": [
    "In this practical, we are going to work with BERT! More specifically, we are going to perform sentiment analysis of movie reviews using a transformer model, have a look under its hood, and try to explain the model predictions using SHAP.\n",
    "\n",
    "Our BERT-variant of choice is [DistilBERT](https://medium.com/huggingface/distilbert-8cf3380435b5), a light-weight transformer whose performance is comparable to Google's [BERT base model](https://arxiv.org/abs/1810.04805)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQQn4R5sZEOC"
   },
   "source": [
    "## Overview\n",
    "\n",
    "In Part 1, we will use an off-the-shelf sentiment analysis pipeline from the Hugging Face [`transformers`](https://huggingface.co/docs/transformers/index) module to classify two movie reviews.\n",
    "\n",
    "In Part 2, we will dissasemble the sentiment analysis pipeline by performing the same analysis as in Part 1 step-by-step.\n",
    "\n",
    "In Part 3, we will open the black box and explore which tokens were most important for DistilBERT's sentiment classification. We do this using [Shapley Additive Explanations \\(SHAP\\)](https://arxiv.org/abs/1705.07874).\n",
    "\n",
    "In Part 4, we will fine-tune DistilBERT on the IMDB movie review dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNB0zNdOpjiP"
   },
   "source": [
    "## Prepare the Colab Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vpq6hPL7XdM"
   },
   "source": [
    "**Fine-tuning a transformer model is quite resource-intensive! Switch your runtime type to GPU T4 under Runtime > Change runtime type.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ysbJuDr4GqU"
   },
   "source": [
    "**Running this practical requires a more recent version of the `accelerate` package than installed by default in Google Colab. Run the code below to upgrade `accelerate`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vHEytt834e1M",
    "outputId": "cf450f56-1a38-4601-f376-e8d09dc5d78a"
   },
   "outputs": [],
   "source": [
    "# !pip install -q -U accelerate # update accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BH3lSfvzp4lW"
   },
   "source": [
    "**Now restart your runtime under Runtime > Restart runtime or by pressing `ctrl + M .` (a pop-up prompt should appear)**\n",
    "\n",
    "**All set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ye3j9o_vY1FL"
   },
   "source": [
    "## Part 1: Off-the-shelf sentiment analysis pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uboYZSOU6DP-"
   },
   "source": [
    "Since sentiment analysis is a popular application, there are off-the-shelf pipelines which we can use to quickly classify documents by sentiment. One such pipeline is part of the Hugging Face `transformers` module.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7CIF8RKZEOD"
   },
   "source": [
    "\n",
    "<blockquote> ðŸ¤— Transformers provides APIs and tools to easily download and train state-of-the-art pretrained models. Using pretrained models can reduce your compute costs, carbon footprint, and save you the time and resources required to train a model from scratch.\n",
    "\n",
    "[ ... ]\n",
    "\n",
    "The pipelines are a great and easy way to use models for inference. These pipelines are objects that abstract most of the complex code from the library, offering a simple API dedicated to several tasks, including Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction and Question Answering. See the task summary for examples of use.\n",
    "\n",
    "[ ... ]\n",
    "\n",
    "The `pipeline()` is the most powerful object encapsulating all other pipelines.\n",
    "\n",
    "\n",
    "</blockquote>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYvuk3B9Yi1B",
    "outputId": "9ac60886-466c-485e-e7ba-74bb6bef78a0"
   },
   "outputs": [],
   "source": [
    "# !pip install -q transformers\n",
    "# !pip install -q Xformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ypwVgVkvJ79T"
   },
   "outputs": [],
   "source": [
    "from transformers import set_seed\n",
    "set_seed(137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9OgWSB-SxYF6"
   },
   "source": [
    "Our BERT model will be distilbert base uncased. Uncased means that the model disregards casing (upper or lower case). Our distilbert version has been fine-tuned for binary sentiment classification using the [Stanford Sentiment Treebank](https://arxiv.org/abs/cs/0506075) (SST-2; Pang and Lee, 2005) corpus. Hence, we can use it off-the-shelf.\n",
    "\n",
    "Pre-trained BERT models are available for many different natural language processing tasks based on the General Language Understanding Evaluation (GLUE) [benchmark resources](https://huggingface.co/datasets/glue)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VqY0cQWra-A_"
   },
   "source": [
    "To showcase how to use the sentiment analysis pipeline, we will compare two relatively complex IMDB reviews of Mark Mylod's 2022 movie *The Menu* (2022). Load the following two reviews:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WC2q6zMgZN_a"
   },
   "outputs": [],
   "source": [
    "review1 = \"The Menu isn't the first to satirise the rich and their incompetence and isn't saying anything new \\\n",
    "but that definitely doesn't prevent it from being a great satire that pokes fun at everything it can in ways that \\\n",
    "are often consistently funny, playful and extremely stylish. Ralph Fiennes gives a terrific performance full of awkward\\\n",
    "unease that only enhances his commanding screen presence. Anya Taylor-Joy is a perfect audience surrogate amongst a sea\\\n",
    "of deliberately unlikeable characters of which the best is Nicholas Hoult whose almost too good at making his character\\\n",
    "hilariously pathetic. Mark Mylod's direction is excellent, the film has more than enough visual style to match the \\\n",
    "pretentiousness of its characters and is really good at building tension. The music by Colin Stetson is fantastic, \\\n",
    "striking a unusual balance between beautiful and unnerving.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "TDhcQaU5cAAX"
   },
   "outputs": [],
   "source": [
    "review2 = \"This looked like an interesting film based on the trailer and the first half of it was just that. \\\n",
    "The tension and suspense was building nicely. There were little dribs and drabs and hints of what might be coming \\\n",
    "without being too obvious. The acting from everyone in the film was good. Even supporting characters with only a few \\\n",
    "lines. Were well realized I remember thinking that I couldn't wait to see where it was all going. Sadly it didn't \\\n",
    "really go anywhere. It all unwound in the second half. The acting was still on but the writing failed. That's the most \\\n",
    "i can say without giving up any spoilers. And that was extra disappointing because the first half was so good. This \\\n",
    "Menu did not deliver the meal as advertised.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUCISi0FNe-B"
   },
   "source": [
    "You can skim the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rO84AwYeNgVs",
    "outputId": "a0d47497-8f4b-4aa8-9d3c-78f4f0e8bedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Menu isn't the first to satirise the rich and their incompetence and isn't saying anything new but that definitely doesn't prevent it from being a great satire that pokes fun at everything it can in ways that are often consistently funny, playful and extremely stylish. Ralph Fiennes gives a terrific performance full of awkwardunease that only enhances his commanding screen presence. Anya Taylor-Joy is a perfect audience surrogate amongst a seaof deliberately unlikeable characters of which the best is Nicholas Hoult whose almost too good at making his characterhilariously pathetic. Mark Mylod's direction is excellent, the film has more than enough visual style to match the pretentiousness of its characters and is really good at building tension. The music by Colin Stetson is fantastic, striking a unusual balance between beautiful and unnerving.\n"
     ]
    }
   ],
   "source": [
    "print(review1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AXbCNrcbNmlZ",
    "outputId": "8bfcefd2-1351-4b96-8bcc-41aeadb3507a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This looked like an interesting film based on the trailer and the first half of it was just that. The tension and suspense was building nicely. There were little dribs and drabs and hints of what might be coming without being too obvious. The acting from everyone in the film was good. Even supporting characters with only a few lines. Were well realized I remember thinking that I couldn't wait to see where it was all going. Sadly it didn't really go anywhere. It all unwound in the second half. The acting was still on but the writing failed. That's the most i can say without giving up any spoilers. And that was extra disappointing because the first half was so good. This Menu did not deliver the meal as advertised.\n"
     ]
    }
   ],
   "source": [
    "print(review2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vysw7hMIPbSd"
   },
   "source": [
    " What is your guess of the sentiment of the following reviews? On the scale 1-10, what rating do you think the respective authors gave the movie?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzJT-qpuOQ-r"
   },
   "source": [
    "**1. Set up and fit a sentiment analysis pipeline to predict the sentiment of the two reviews. Define the model as `'distilbert-base-uncased-finetuned-sst-2-english'`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "d667578aee1a4d399127861139117c62",
      "6326e20cf6924f44b1de10032f718cc1",
      "3974aa6f392546ad9e30e82fbf41fd8e",
      "c768aa1f9ab24e8fa5de1ba28c801156",
      "1be6cc5cf26f4bd2858d239b277c195e",
      "d7d6ad94767c48bb8693aaf0bbe9de8f",
      "15079db1eb574fa1a408971ebe7cfd7b",
      "37aff52129bb4b24ba2d73cf602c3e42",
      "e619c1ae4ce64a53b1b672c075b24f92",
      "e38783f2c33e4b1d80a0627f399c4bf9",
      "9a661d1ec5c0498ea958e6db3797e671",
      "7efa8ab0f603412ea91e4116b48427f5",
      "dc2e057baf724752ae87a73e4be09c19",
      "a7b2d29190f4455588781aec8bbf2bba",
      "b61ea573d05742d5846b689008dc6149",
      "385a040adf5d47e9ae56725357a38c76",
      "2271ef1c900543a0aec50a9dbe346353",
      "865fb676de1f4780a809131adf7211d0",
      "b21b070a805644529f54c2859bfa91a5",
      "dcccc9aff8ce4cf1b0b1fee3456e7bc1",
      "d5f463a71aeb4c75ad2e86a10466b5fc",
      "6a9815f5032b4221b6db7291309b9167",
      "b8e9f859abf742e286f0d8e9c55d399c",
      "6a2109505286491d859366065dddf6c4",
      "769fe58552f54640b6ea084b97cca6eb",
      "fd2fb323fdb94be08638b85ee91e565d",
      "e4ddc837b9364356b14618a5f7326f36",
      "a285b5da6d4346f8a5d5d22ca7ea5474",
      "6e944a3b539f49f1a202b275c1cbbc92",
      "ead5803cc38045dea401a0858d9412af",
      "25d99d8db4a84a1c875393f1e31f3910",
      "9851edff23884d819252e629030e63b0",
      "b9dd8462a1bf438e89f6e98b17ce7404",
      "0de245fd9829422dba66e71021acf478",
      "137b314f895846419177e69581fc575b",
      "90cd8575fb2c43aea2f9331bbfe68593",
      "5a6581270b9a4c048b2a2abe30dfdfe5",
      "0ac12a227bb24ce082dfd9cc81b11718",
      "306aef2e32bc4843bced9c420a1ffaaf",
      "cad56d1e8c444dba89d8fcb87d8ad12a",
      "ed8e6c73053248dba7c46d7429e1caac",
      "f97b0ad09dfb4aaebf5f09202cb03983",
      "e264487b7a9e4aebb793fa49800120ec",
      "12531c4e91c240d99ad4c7a68d6dd899"
     ]
    },
    "id": "a4j8LAzaInBY",
    "outputId": "2099980d-3bc5-4772-9568-45ed2aa116ee"
   },
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model = 'distilbert-base-uncased-finetuned-sst-2-english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3TDYROrJL4H",
    "outputId": "53f3da7f-1aae-4c93-f29b-5647e7ae7d02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9983012080192566}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(review1) # predict sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bv14QJTBJYfo",
    "outputId": "90e2bae9-7e18-44bc-b80c-ebef03b6796d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9622442722320557}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(review2) # predict sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwbyGScNJntU"
   },
   "source": [
    "For each review, we see the output label and the associated probability.\n",
    "\n",
    "Do you agree with model predictions?\n",
    "\n",
    "Here is the ground truth:\n",
    "\n",
    "[Review 1](https://www.imdb.com/review/rw8682076/?ref_=tt_urv) is a positive review with a rating of 8/10.\n",
    "\n",
    "[Review 2](https://www.imdb.com/review/rw8693249/?ref_=tt_urv) is a negative review with a rating of 4/10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXI_OkQN8Inz"
   },
   "source": [
    "For each review, we see the output label, and the associated probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wARXcSJHOpYz"
   },
   "source": [
    "Now we are going to show you how to build your own sentiment analysis pipeline from scratch. In practice, you can use the already existing one, but it is helpful to understand the steps associated with setting up a transformer-based pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRH2xXIwoatd"
   },
   "source": [
    "## Part 2: Sentiment Analysis Pipeline - Deconstructed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ctpjTGebv2Zj"
   },
   "source": [
    "Same analysis on the same two reviews - this time step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5eJdi5w8tP5"
   },
   "source": [
    "**2. Define the tokenizer and model. For the tokenizer, use the pretrained DistilBERT tokenizer (`DistilBertTokenizer.from_pretrained`) and for the model use `\"distilbert-base-uncased-finetuned-sst-2-english\"`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "z-2mjSExojVU"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uGze_MSygSP"
   },
   "source": [
    "**3. Tokenize the `review1` and `review2` objects. Pad and truncate the sequences, and return PyTorch (`pt`) tensors. Save the output object as `encoding`.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ySmLxj2qsed0"
   },
   "outputs": [],
   "source": [
    "encoding = tokenizer([review1, review2], padding = True, truncation = True, return_tensors = 'pt') # tokenize the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7rm7x9S9Lm_"
   },
   "source": [
    "BERT and several other transformer models use tokenizers based on [WordPiece](https://huggingface.co/learn/nlp-course/chapter6/6?fw=pt), a subword tokenization algorithm. The main advantage of a subword tokenizer is that it interpolates between word-based and character-based tokenization. Common words get a slot in the vocabulary, but the tokenizer can fall back to word pieces and individual characters for unknown words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lOYimGp15Qy"
   },
   "source": [
    "Since batched inputs (our reviews) are of different lengths, they cannot be converted to fixed-size tensors to befed to the model.\n",
    "\n",
    "There are two main strategies for solving this problem -- *padding* and *truncation*.\n",
    "\n",
    "In order to create rectangular tensors from batches of varying lengths, padding adds a special padding token to ensure shorter sequences will have the same length as either the longest sequence in a batch or the maximum length accepted by the model. Truncation works in the other direction by truncating long sequences.\n",
    "\n",
    "`padding = True`: pad to the longest sequence in the batch (no padding is applied if you only provide a single sequence).\n",
    "\n",
    "`truncation = True`: truncate to a maximum length specified by the max_length argument or the maximum length accepted by the model if no max_length is provided (max_length=None)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltSpVedY0uge"
   },
   "source": [
    "**4. Inspect the `encoding` object by prining the first reveiw's input ids.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LLvKx1Y5z1zs",
    "outputId": "3fe5613a-ab72-4ca2-9c2a-282343db551f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  1996, 12183,  3475,  1005,  1056,  1996,  2034,  2000,  2938,\n",
      "        15735,  3366,  1996,  4138,  1998,  2037,  4297, 25377, 12870,  5897,\n",
      "         1998,  3475,  1005,  1056,  3038,  2505,  2047,  2021,  2008,  5791,\n",
      "         2987,  1005,  1056,  4652,  2009,  2013,  2108,  1037,  2307, 18312,\n",
      "         2008, 26202,  2015,  4569,  2012,  2673,  2009,  2064,  1999,  3971,\n",
      "         2008,  2024,  2411, 10862,  6057,  1010, 18378,  1998,  5186,  2358,\n",
      "         8516,  4509,  1012,  6798, 10882, 24336,  2015,  3957,  1037, 27547,\n",
      "         2836,  2440,  1997,  9596,  9816, 11022,  2008,  2069, 11598,  2015,\n",
      "         2010,  7991,  3898,  3739,  1012, 21728,  4202,  1011,  6569,  2003,\n",
      "         1037,  3819,  4378,  7505, 21799,  5921,  1037,  2712, 11253,  9969,\n",
      "         4406,  3085,  3494,  1997,  2029,  1996,  2190,  2003,  6141,  7570,\n",
      "        11314,  3005,  2471,  2205,  2204,  2012,  2437,  2010,  2839, 26415,\n",
      "         9488, 27191, 17203,  1012,  2928,  2026,  4135,  2094,  1005,  1055,\n",
      "         3257,  2003,  6581,  1010,  1996,  2143,  2038,  2062,  2084,  2438,\n",
      "         5107,  2806,  2000,  2674,  1996,  3653,  6528, 20771,  2791,  1997,\n",
      "         2049,  3494,  1998,  2003,  2428,  2204,  2012,  2311,  6980,  1012,\n",
      "         1996,  2189,  2011,  6972, 26261, 25656,  2003, 10392,  1010,  8478,\n",
      "         1037,  5866,  5703,  2090,  3376,  1998,  4895,  3678,  6455,  1012,\n",
      "          102])\n"
     ]
    }
   ],
   "source": [
    "print(encoding['input_ids'][0]) # first review's input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s4m7V_4w94hb"
   },
   "source": [
    "We see that BERT assigns a unique id to each token (`input_ids`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzxWd0Q_312z"
   },
   "source": [
    "**5. Convert first review's input ids to tokens using `convert_ids_to_tokens` to see how the text got tokenized.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qTbQKpNbpRjf",
    "outputId": "5f47ede6-6786-4d8f-ff35-853e5c304e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'the', 'menu', 'isn', \"'\", 't', 'the', 'first', 'to', 'sat', '##iri', '##se', 'the', 'rich', 'and', 'their', 'inc', '##omp', '##ete', '##nce', 'and', 'isn', \"'\", 't', 'saying', 'anything', 'new', 'but', 'that', 'definitely', 'doesn', \"'\", 't', 'prevent', 'it', 'from', 'being', 'a', 'great', 'satire', 'that', 'poke', '##s', 'fun', 'at', 'everything', 'it', 'can', 'in', 'ways', 'that', 'are', 'often', 'consistently', 'funny', ',', 'playful', 'and', 'extremely', 'st', '##yl', '##ish', '.', 'ralph', 'fi', '##enne', '##s', 'gives', 'a', 'terrific', 'performance', 'full', 'of', 'awkward', '##une', '##ase', 'that', 'only', 'enhance', '##s', 'his', 'commanding', 'screen', 'presence', '.', 'anya', 'taylor', '-', 'joy', 'is', 'a', 'perfect', 'audience', 'sur', '##rogate', 'amongst', 'a', 'sea', '##of', 'deliberately', 'unlike', '##able', 'characters', 'of', 'which', 'the', 'best', 'is', 'nicholas', 'ho', '##ult', 'whose', 'almost', 'too', 'good', 'at', 'making', 'his', 'character', '##hila', '##rio', '##usly', 'pathetic', '.', 'mark', 'my', '##lo', '##d', \"'\", 's', 'direction', 'is', 'excellent', ',', 'the', 'film', 'has', 'more', 'than', 'enough', 'visual', 'style', 'to', 'match', 'the', 'pre', '##ten', '##tious', '##ness', 'of', 'its', 'characters', 'and', 'is', 'really', 'good', 'at', 'building', 'tension', '.', 'the', 'music', 'by', 'colin', 'ste', '##tson', 'is', 'fantastic', ',', 'striking', 'a', 'unusual', 'balance', 'between', 'beautiful', 'and', 'un', '##ner', '##ving', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])) # first review's tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S2v4wwQg0Gfk"
   },
   "source": [
    "Note that BERT-based models also operate with special tokens:\n",
    "\n",
    "\n",
    "| Token      | Token ID | Meaning                                 |\n",
    "|:----------:|:--------:|:---------------------------------------:|\n",
    "| `[CLS]`    | `101`    | Beginning of input                     |\n",
    "| `[SEP]`    | `102`    | End of input or sentence               |\n",
    "| `[MASK]`   | `103`    | Masked tokens the model should predict |\n",
    "| `[PAD]`    | `0`      | Padding                                 |\n",
    "| `[UNK]`    | `100`    | Unknown token not in training data     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvNqOFSQA-eG"
   },
   "source": [
    "**6. Predict sentiment of the two reviews. In order to do this, import `torch`, and define the `output` object using the model, input ids and attention mask.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hflstHhN_fSq"
   },
   "source": [
    "Now we are ready to do some sentiment prediction. We import `torch`, define our model by feeding it `input_ids`, `attention_mask`. The attention mask is a binary tensor indicating the position of the padded indices so that the model does not attend to them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YwGxY_702W-I"
   },
   "outputs": [],
   "source": [
    "# prediction of sentiment\n",
    "import torch\n",
    "output = model(input_ids = encoding['input_ids'], attention_mask = encoding['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yIt24BJOA32e",
    "outputId": "efa88a5f-7cfc-4606-88d2-9ab4a713c2ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted logits:\n",
      "\n",
      " tensor([[-3.1107,  3.2654],\n",
      "        [ 1.8161, -1.4221]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted logits:\\n\\n\", output['logits']) # logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jj7PXqV3A2Aq",
    "outputId": "b676f608-bb5b-4b53-971f-bc531b3545ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted probabilities:\n",
      "\n",
      " tensor([[0.0017, 0.9983],\n",
      "        [0.9622, 0.0378]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predicted probabilities:\\n\\n\", torch.nn.functional.softmax(output['logits'], dim=-1)) # from logits to probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ietl5miAAzZS",
    "outputId": "85ba2a32-e79e-4f71-d994-7c12891aa9ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted classes:\n",
      " tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "prediction = torch.argmax(output['logits'], 1) # from logits to binary class\n",
    "print(\"Predicted classes:\\n\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XDre3gwyAeCP"
   },
   "source": [
    "We see that our output sentiment and probabilities are the same as when using off-the-shelf sentiment classification pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wRenWoaK2NRl"
   },
   "source": [
    "## Part 3: Feature importance with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oeD2f17iBfye"
   },
   "source": [
    "Now that we have classified our two reviews, we might want to explain DistilBERT's predictions using [Shapley Additive Values (SHAP)](https://shap.readthedocs.io/en/latest/).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjTx1JVtBrXb"
   },
   "source": [
    "**7. Install the `shap` module, import `shap.Explainer` and feed it the `sentiment_pipeline` model. Pass the two movie reviews as input for the explainer.**\n",
    "\n",
    "*Note. The computation of Shapley values for DistilBERT explaining our two reviews should take about 4 minutes, but can be very computationally intensive in most real life applications.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "1d28fd574cfe47048a74945839f6cd18",
      "a2819d26b47d4823b15203cb55f5ecf9",
      "3e3e17baab7e42d5a9685a020f80d487",
      "0af604481b334bacb5fc8dab3a276b07",
      "9a803c2c41bf451192e11f47a7dd2bb5",
      "5f4e9f59ba6c4f8bb22e3300f122c1c4",
      "fb65be6057d54b7cba78279672922379",
      "f597fba1d23d4b07bf78c0f517c51061",
      "91023dfb5823484abb16b300a29129dc",
      "6e36a14499f142eaa7b93508cfa8343e",
      "e2d5385e78884f5ba6437a9bf40f8bb6",
      "21336a70038147bf88ac9a629d520637",
      "afd0ec5ddc944856ad8ef8ae01b1cad8",
      "408b390b96b2491199bf0227426da0fc",
      "40835c6d8b4549da98b5af9ad0b7d04a",
      "7bc360b5e27c486c9d3d1cc0cea10a72",
      "7513a6327bfc47489e99811b85e02c49",
      "bc504d78464b4a39abbf636001f52c6f",
      "32086218ed354b88bf99fc3f0eeeff1e",
      "5a6ef50cabd14e0086ff6ea954da7c14",
      "a45c490a6a6f45e8a068285ad5ee827c",
      "79887f6b8d214ed08e99c50bcba4d5d5"
     ]
    },
    "id": "QIycrlpZE4y3",
    "outputId": "a205fcc4-8ee1-4e61-df8b-67a4dd0d38f0"
   },
   "outputs": [],
   "source": [
    "# !pip install -q shap\n",
    "import shap\n",
    "explainer = shap.Explainer(sentiment_pipeline)\n",
    "shap_values = explainer([review1, review2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3UZ09Z8BQlD"
   },
   "source": [
    "**8. A nice thing about the `shap` module is that it comes with a built-in visualizer. Use `shap.plots.text` to visualize the shap values for the first and the second movie review.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "gim5zsViSSHj",
    "outputId": "ad82f11a-e18b-4608-c295-e9faccb770f6"
   },
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[0]) # first review"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/shap1.jpg\" alt=\"logo\" align=\"center\"  />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "hxgU_ohFSWV3",
    "outputId": "485ce5e1-1ed2-46e5-ca40-ee1a88918525"
   },
   "outputs": [],
   "source": [
    "shap.plots.text(shap_values[1]) # second review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/shap1.jpg\" alt=\"logo\" align=\"center\"  />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xSoT7OOyU9ez"
   },
   "source": [
    "## Part 4: Fine-tuning BERT using the IMDb dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZOHD31MeVE3S"
   },
   "source": [
    "Now let's do a sentiment analysis of the IMDB dataset using the sentiment analysis pipeline.\n",
    "\n",
    "Since the DistilBERT we are using was trained on the Stanford Sentiment Treebank (SST) dataset, we also fine-tune our model for IMDb movie reviews. In practice, this might not be neccesary for this particular application, but might be good to see how it can be done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pt9942EL5gZ3",
    "outputId": "6a9dbf8f-0585-489b-b869-73789583cc19"
   },
   "outputs": [],
   "source": [
    "# !pip install -q datasets\n",
    "# !pip install -q transformers\n",
    "# !pip install -q evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "DncOpHHKnuKq"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KbUDVZqEGYl"
   },
   "source": [
    "**9. Load the IMDb dataset and sample 10% of the `train` and `test`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 239,
     "referenced_widgets": [
      "79aae160f13a41839de73be7cd76e5f3",
      "e3cc35061b0a42b595be0a7720cdd579",
      "2b42ce24286f49af99298198c6d827c6",
      "7c5cfe7fa9784ae4a3b297c4c5ff4ee8",
      "ad7aa3b77f724e58bef7eda5c63835aa",
      "d10e4651f41545b29c86dbdebc313d68",
      "71f7e0824dbb4b03972a80f4d260cf97",
      "737287132b7e4084a6604a80ce5bf0dc",
      "4a749915cd844569868d293e7047903d",
      "9e028c1983854b61b685ee1eb003788f",
      "ed6b0b41c2a44ab08fddf5809a688dad",
      "4f7a737be47d4f859472c595dc3b43ff",
      "cc98347ce3124817827803f1671cebff",
      "bef076771eff4738892cb6fb1af55f85",
      "718e9162227643e9ba6088c42e1414ee",
      "c60a5eb2f3944bf69b2eec4563768e53",
      "c969bc0784af48fca4acadccdb401b15",
      "49e8ce4568824141a758e33715079502",
      "86ecc9a8dfba4eb6b45b817dd8f4a71a",
      "c858be62f8dd4136b08278a931a0f863",
      "8fa7fd415ee040f5b009f26c931016c7",
      "704f8ef3240f4b0690dcb195f231e3f2",
      "7e38d5cad0a2413bbcefbde5236ee628",
      "0a4f16c65df246549a7a4da75bba5db1",
      "84b8e038903049079a4e9098340a5429",
      "b71a0297fdc04240adae4f9551b03a0b",
      "edcea6e9013e469a9f38548e6e56802d",
      "17e16be9e932415e8d3ec46e0c759a0b",
      "a2096c3c2f5b40cc9a238e2926445094",
      "0dea843b56c147f0b03fd967d4e95824",
      "6a9b446faaee47168a734077ba144d9c",
      "5897b143bf7842589eb418d100a310b2",
      "86a8721d748c49e5a79972d14f6da60c",
      "3340de31dfe84076a4db189c17e89f92",
      "f327ad38966646d0b4481d4eebd6398f",
      "a05ec543dafb4dd5a2d9203ae92c66c9",
      "0cb2aca2cc8d48579d2eb193cbf390ac",
      "194797a2f1314c9d94c564199c6e7916",
      "40fd2183867345099f99325458f8f9e2",
      "d4b4c1d5936f472588f429f05ff7a959",
      "33cab7dac9eb4a1a925d1f43d9eefa84",
      "b56838f455e743fab612e27c95b5f27d",
      "78477f0b7a97448da0dfa839dfe483d4",
      "d72faeaf95074e59a4c08e8b9b2e1701",
      "137df6402d0a451dae572fb9e995effe",
      "bbaad46314ed463a9a4a2ea106f31263",
      "38fa04e43a3a414fa95c76314e764975",
      "44cae7a29bcd40febf388b0c0fae1388",
      "feaeeffcd0f848a8a532ed0831a74105",
      "4d4bfff3d3fa43478226593e9c62c0e7",
      "baa227b7edf5466da1cc2bd5738bf3ce",
      "8e5d457db2a548bf9cf8e331d2d3f411",
      "41813ca26af44d5fbe2971d48bf6b7bd",
      "d759419d311c4e179c1b9e492f9f8e91",
      "23733aca4fe949359856fbbf4a5a8bf0",
      "f165557150cc48f2b6286ccce66f9d84",
      "f29c869036954a83bce89e9536052ac1",
      "f173d5e6586f4a4199f6abe417b6e4be",
      "af0ddcec1c90442d968896256d65d039",
      "3059d61565d2461baf16975fdabbb009",
      "94facbce47054a3ea3ee0c25ed42a83f",
      "d7c3746e3b724c4fbffee1d724be8655",
      "94d719bb1e3e479fb405666420eb380f",
      "c566457e1f154e9e81bf6717e6356630",
      "484e7f69c6d745b1a869f767aa782357",
      "829f8aac5bfe4278bd17004016eaf600",
      "d31df29194bd44029a88a511804ea525",
      "3ef8197a5a994017ad53a2fe25a1471b",
      "09639d0ea9884e9da54803c0cbf0f12e",
      "880441f648f7400b8b39547eaf756f65",
      "40af266876d640f28d7ce2ce61a4be9b",
      "9e8bab6c58464c428505b1ee846eb3b8",
      "1dae33e9ea6540d1901913a2f1a2f0cb",
      "5b95b39222024327b708eb1e8ec9325d",
      "98a83b9a48cb4df69a1e4ed95494ab87",
      "73e25b47c2e242ee8db2c2efa23fced5",
      "cacfe745c0b146fc9d0ae35b1cba22e6",
      "1d0d5590998d4b4595170e0512178116",
      "c9264e3d31104b73a8399eb927543803",
      "f5e3e0a1b9cc4d7ab3d95e98b58ac206",
      "65ca43e9c65f485d827098639124f9cf",
      "5dbddec6a5dd489ab737e4fbe616a8aa",
      "863d114cd5a84dc18f37fe499eed083e",
      "73a534d44e9441c19d09c9739d9d3b73",
      "f1e9e35ed0a947eaa795346f08474cc1",
      "e914364e1dde4ecaba2c00cc9acc5dbf",
      "ac37dc58106849ff86bfe5f0604842be",
      "21723e7af8a94d1cbe7c183a0dda9e5d"
     ]
    },
    "id": "YE4dkm6gn3TS",
    "outputId": "f7229e1d-50e4-4025-d0eb-a82cabc8fa0b"
   },
   "outputs": [],
   "source": [
    "imdb = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yiZslWYaqMuY",
    "outputId": "a2987274-4c22-422d-a429-f336633160fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichÃ©d and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb[\"test\"][0] # examine the first instance in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZ_3sMJFrMze",
    "outputId": "206c33db-f8c7-4522-d064-a9c315f0c556"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (25000, 2), 'test': (25000, 2), 'unsupervised': (50000, 2)}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.shape # inspect dimensions full data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQLVsVSnxcRN"
   },
   "source": [
    "Because fine-tuning on the entire IMDb dataset would be too resource-intensive to run in this practical, we will work with a randomly sampled 10% of the original train and test dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "pHHTV0lMyjQP"
   },
   "outputs": [],
   "source": [
    "imdb_sample = imdb\n",
    "imdb_sample['train'] = imdb['train'].shuffle(seed=42).select(range(int(0.1*len(imdb['train']))))\n",
    "imdb_sample['test'] = imdb['test'].shuffle(seed=42).select(range(int(0.1*len(imdb['test']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A2vgPnnK0QLG",
    "outputId": "c8c43f8e-74fe-45e9-b254-a0e52f4fa042"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': (2500, 2), 'test': (2500, 2), 'unsupervised': (5000, 2)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9f58m83tpcQ"
   },
   "source": [
    "The next step is to load a DistilBERT tokenizer to preprocess the text field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "05ZaeUy7ohY2"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBezCubRtlvE"
   },
   "source": [
    "Create a preprocessing function to tokenize text and truncate sequences to be no longer than DistilBERTâ€™s maximum input length:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nPGdmGV5pHrb"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E2tZUbtEtttV"
   },
   "source": [
    "To apply the preprocessing function over the entire dataset, use Datasets map function. You can speed up map by setting `batched=True` to process multiple elements of the dataset at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "171d90bc9c2244f488e101d6c0098826",
      "800aed0178d14ee9b44b629228ab00f4",
      "a471f52fbe634b7085a3f1e315c9ba5c",
      "1f568f44bc7046cabeffb1757f54ebf4",
      "a423c524ea634515af244fe97c6eb517",
      "0088b4daf4ed466e9a4f76047930bd2f",
      "3f96eb23bf1545a6bf6b764dc0cbfd36",
      "41bec8a2923140eba231a2b5ad681913",
      "a76df22099ac4812bbdaaf3d206a148f",
      "6dcb7e93033248569ad204d95d519e8c",
      "daba47510eba4f8f9ab5e1b43ba7d018",
      "cb08369bba4d4278af0da6990d94d269",
      "fcbd242b1df84532b0d0900a478629d0",
      "7395fee7a2094df2870b528e10673b57",
      "a5b7130c3e75441e83e7698a1e919732",
      "28c9eeb7ee4a4724babf9f9d84c2a6e1",
      "8d9b839a0b6e4c168be91f1efdb4507f",
      "5508fcf294624db9afe1e62ee28475f7",
      "a761b359fd13450cbaddbf90142308f9",
      "908b059265f04ce6b7f24247e966c91e",
      "c66e8f3a1abd40b79f3b6938677531f8",
      "a35aac2768f04051a441d0ee394d040e",
      "f6e43b0cc5e1410f9c53f952197dbf66",
      "f1546d23fae749818064e0bfec5bc84e",
      "f31f14c689b24a14b6f5d4b60ede031c",
      "26cc939682c546f7bc247c707463b1e1",
      "c77923d855e24c53a83701076437957b",
      "2662b3ddec0d46538e2535f3b6ee29bb",
      "5dc9181780c44a69a492cd7b38311774",
      "33902bfcddc54e2d815c72061b64ef10",
      "b10ac796f8364a85bbbdeacc68a6012c",
      "d8c9211bbdb044ee80427735b4e5ee3c",
      "9ee42a7a041a4200b45fa345c24d3e47"
     ]
    },
    "id": "xYRO_8-jqEX0",
    "outputId": "1b5e4833-ba75-44cd-e507-880e49352fe3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_imdb = imdb_sample.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIv748v8t37Q"
   },
   "source": [
    "Including a metric during training is often helpful for evaluating your modelâ€™s performance. You can quickly load a evaluation method with the `evaluate` library. For this task, load the accuracy metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "b443caa216db48959bc3c8cb909d03f8",
      "fc408168755d4450bf986abb40f47c1b",
      "78be13071603457cb361d1a3bdee9c1f",
      "fa98f570fde44856bf5bc38dbbdaa3f1",
      "723f0731c0bc4345b5d11b5cce686264",
      "552e90c5506841809c53fbc0cb78d7a7",
      "ab85497f718e4a26a013312666fc50a3",
      "727ffb7e9dc64165beba47b383b21589",
      "801477928e4c4813add85e11d0558871",
      "9d59d07233444db4bda13204ccecd4f2",
      "50feddc3c1794f1aa146b2613a51843e"
     ]
    },
    "id": "eDvz4XWRr_w6",
    "outputId": "bc1d30d8-c4bd-4b69-cfea-d61927576d09"
   },
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "KoSZwiaisQnb"
   },
   "outputs": [],
   "source": [
    "id2label = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
    "label2id = {\"NEGATIVE\": 0, \"POSITIVE\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "scVXS03ysdJo"
   },
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased-finetuned-sst-2-english\", num_labels=2, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "id": "vzSV8H_ZsyvL",
    "outputId": "959411a3-d3bb-4ccf-bf72-ea98eb4f8e94"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"tuned_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps = 100,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_imdb[\"train\"],\n",
    "    eval_dataset=tokenized_imdb[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics)\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Epoch | Training Loss | Validation Loss | Accuracy |\n",
    "|-------|---------------|-----------------|----------|\n",
    "|   1   |    0.290000   |    0.232040     | 0.909600 |\n",
    "|   2   |    0.138300   |    0.297178     | 0.910400 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozBOW9rhlain",
    "outputId": "67e14783-7da4-4de7-a030-ffecc7f7abde"
   },
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"tuned_model\")\n",
    "classifier(\"The movie was good.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'label': 'POSITIVE', 'score': 0.9994469285011292}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f23XdC-KrSHD"
   },
   "source": [
    "## Remember: Be on the lookout for bias and other limitations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HqVTZb6Ne1J"
   },
   "source": [
    "Pre-trained transformer models have been made available for many different tasks and by many different people. It is important to be aware that there may be bias and other limitations in the models that could affect your results.\n",
    "\n",
    "DistilBERT is known to produce biased predictions that target underrepresented populations. For instance, for sentences like This film was filmed in COUNTRY, DistilBERT for binary classification will give radically different probabilities for the positive label depending on the country (0.89 if the country is France, but 0.08 if the country is Afghanistan) when nothing in the input indicates such a strong semantic shift.\n",
    "\n",
    "See:\n",
    "\n",
    "[Risks, Limitations and Biases](https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english#risks-limitations-and-biases)\n",
    "\n",
    "[AurÃ©lien GÃ©ron's Sentiment Bias Map](https://colab.research.google.com/gist/ageron/fb2f64fb145b4bc7c49efc97e5f114d3/biasmap.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdEyx4qPtCvj",
    "outputId": "f52fe3bd-b1f5-4a09-f228-bc1e8373681c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9987333416938782}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(\"French movie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ugdfp6hq0TgG",
    "outputId": "11950855-7dfd-483f-b3d6-95428ed8f68a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.6413726806640625}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline(\"Iraqi movie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-VMG_wsO4Jc"
   },
   "source": [
    "When in doubt fine-tune and use feature importance measures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga_7GpIzTDU2"
   },
   "source": [
    "## Further reading / materials\n",
    "\n",
    "\n",
    "\n",
    "*   How to fine-tune a model: https://huggingface.co/docs/transformers/training\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQGVaw8OcuDj"
   },
   "source": [
    "## Credits\n",
    "\n",
    "Many code and quote blocks are adapted from the [HuggingFace Documentation website](https://huggingface.co/docs/). The website contains a lot of additional information and is a great resource for learners."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
