{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dELWpyou789C"
   },
   "source": [
    "# Impractical 5: Word Embeddings\n",
    "#### Dong Nguyen\n",
    "<img src=\"img/uu_logo.png\" alt=\"logo\" align=\"right\" title=\"UU\" width=\"50\" height=\"20\" />\n",
    "\n",
    "#### Applied Text Mining - Utrecht Summer School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation\n",
    "\n",
    "If you're using Google Colab, then you should be able to run these commands directly. Otherwise, make sure you have `sklearn`, `matplotlib` and `numpy` installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hX_spMIk9BQF"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np    \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import linalg as LA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgw0Ld6kv9Ku"
   },
   "source": [
    "# First install the gensim library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0tEUKDfxJ5Y"
   },
   "source": [
    "In this practical session we're going to use the [gensim](https://radimrehurek.com/gensim/) library. This library offers a variety of methods to read\n",
    "in pre-trained word embeddings as well as train your own.\n",
    "\n",
    "The website contains a lot of documentation, for example here: https://radimrehurek.com/gensim/auto_examples/index.html#documentation\n",
    "\n",
    "If gensim isn't installed yet, you can use the following command:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUHdt_DtvrA3"
   },
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfk4o1Cebn-J"
   },
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKUfWy0nwG0U"
   },
   "source": [
    "# Reading in a pre-trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79Mb6_c9wwvt"
   },
   "source": [
    "First we load in a pre-trained GloVe model. Note: this can take around five minutes.\n",
    "\n",
    "See https://github.com/RaRe-Technologies/gensim-data for an overview of the models you can try. For example\n",
    "\n",
    "*   word2vec-google-news-300: word2vec trained on Google news. 1662 MB.\n",
    "*   glove-twitter-200: trained on Twitter: 758 MB \n",
    "\n",
    "We're going to start with `glove-wiki-gigaword-300` which\n",
    "is 376.1MB to download. These embeddings are trained on \n",
    "Wikipedia (2014) and the Gigaword corpus, a large collection\n",
    "of newswire text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xs4LeLkav_xy",
    "outputId": "7d30a1ed-e861-4856-db7e-7642bc911335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "wv = api.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "91pmPOTX4bmE"
   },
   "source": [
    "# Exploring the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luAJI20EZfVM"
   },
   "source": [
    "How many words does the vocabulary contain?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCYQx2rzamAe"
   },
   "source": [
    "Is '*utrecht*' in the vocabulary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWqjHy7JaCAq"
   },
   "source": [
    "Print a word embedding. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hYuk_2KaLO-"
   },
   "source": [
    "How many dimensions does this embedding have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02IVqpksawKL"
   },
   "source": [
    "**Question:** Explore the embeddings for a few other words. Can you find words that are *not* in the vocabulary? \n",
    "\n",
    "(For example, think of uncommon words, misspellings, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "omCh8m2k1kMd"
   },
   "source": [
    "# Vector arithmethics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OmIVSe-c1pOA"
   },
   "source": [
    "We can calculate the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) between two words in this way:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB1u026w1y4y"
   },
   "source": [
    "*Optional*: cosine similarity is the same as the dot product between the normalized word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfd3Gy5O30_U"
   },
   "source": [
    "A normalized embedding has a L2 norm (length) of 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2qWG2llbX6Q"
   },
   "source": [
    "# Similarity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSFauHoA4xF9"
   },
   "source": [
    "Print the top 5 most similar words to car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YljWEl6W44jN"
   },
   "source": [
    "**Question**: What are the top 5 most similar words to *cat*?  And to *king*? And to *fast*? What kind of words often appear in the top? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVBB1MoOczHp"
   },
   "source": [
    "Now calculate the similarities between two words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eTy98KEIdn1S"
   },
   "source": [
    "We can calculate the cosine similarity between a list of word pairs and correlate these with human ratings. One such dataset with human ratings is called WordSim353.\n",
    "\n",
    "**Goto** https://github.com/RaRe-Technologies/gensim/blob/develop/gensim/test/test_data/wordsim353.tsv to get a sense of the data. \n",
    "\n",
    "\n",
    "Gensim already implements a method to evaluate a word embedding model using this data. \n",
    "* It calculates the cosine similarity between each word pair\n",
    "* It calculates both the Spearman and Pearson correlation coefficient between the cosine similarities and human judgements\n",
    "\n",
    "See https://radimrehurek.com/gensim/models/keyedvectors.html for a description of the methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3hbA_Pd5m2Y"
   },
   "source": [
    "# Analogies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_wpOgoulf_mh"
   },
   "source": [
    "Man is to woman as king is to. ..?\n",
    "\n",
    "This can be converted into vector arithmethics:\n",
    "\n",
    "```\n",
    "king - ? = man - woman.\n",
    "\n",
    "king - man + woman = ?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QpczXwlgUGW"
   },
   "source": [
    "france - paris + amsterdam = ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V_qTUAGjgbdP"
   },
   "source": [
    "Note that it we would just retrieve the most similar words to '*amsterdam*' we would receive a different result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "plZLOUP2giIk"
   },
   "source": [
    "cat is to cats as girl is to ?\n",
    "\n",
    "```\n",
    "girl - ? = cat - cats\n",
    "girl - cat + cats = ?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fsH7_DEh8Zt"
   },
   "source": [
    "Compare against a baseline. What if we would just have retrieved the most similar words to '*girl*'?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdTPXa2M8svY"
   },
   "source": [
    "**Question**: Try a few of your own analogies, do you get the expected answer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z_2LyUAiHm8"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDnfe0x_9izp"
   },
   "source": [
    "We can't visualize embeddings in their raw format, because of their\n",
    "high dimensionality. However, we can use dimensionality reduction\n",
    "techniques such as PCA to project them onto a 2D space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BOVm0bj8AKtY"
   },
   "source": [
    "**Question**: What do you notice in this plot? Do the distances between the words make sense? Any surprises? Feel free to add your own words!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viKrIg1LAlnW"
   },
   "source": [
    "# Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m02uJ_taNhbk"
   },
   "source": [
    "Is *math* more associated with male or female words?\n",
    "\n",
    "Compute the average cosine similarity between the target word\n",
    "and the set of attribute words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLBpdjSON1UW"
   },
   "source": [
    "What about *poetry*?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fof7yee6KNz4"
   },
   "source": [
    "#Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYkoAJXvKb4U"
   },
   "source": [
    "Repeat this analysis but now with the GloVe model trained on Twitter data, \n",
    "e.g. `glove-twitter-50`.\n",
    "\n",
    "* Which model obtains better performance on the word similarity task? (WordSim353?)\n",
    "* What other differences do you observe? (e.g. think of the vocabulary, biases, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lg5NPxBoOtia"
   },
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKg2ssDeRi93"
   },
   "source": [
    "(only if you have time, this can take a while (11 min?))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wiQ9AbR6RmFc"
   },
   "source": [
    "Load in a fastText model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tL4pC2stRuNE"
   },
   "source": [
    "Usage is very similar to before. For example, we can calulcate the similarity\n",
    "between two words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvADpGHIR2GB"
   },
   "source": [
    "**Question** How does this compare to the similarity scores you obtained\n",
    "with the other models you tried?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "word_embeddings_summerschool.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
