{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning for multiclass text classification\n",
    "#### Applied Text Mining - Utrecht Summer School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the sixth practical of the course “Applied Text Mining”. In this practical, we will apply a various deep learning models for multiclass classification. We will work with the 20 Newsgroups data set from the sklearn library and will apply deep learning models on that using the Keras library. \n",
    "\n",
    "The 20 Newsgroups data set is a collection of approximately 20,000 newsgroup documents, partitioned (nearly) evenly across 20 different newsgroups. It was originally collected by Ken Lang, and it has become a popular data set for experiments in text applications of machine learning techniques.\n",
    "\n",
    "On the other hand, Keras is a deep learning and neural networks API by François Chollet which is capable of running on top of Tensorflow (Google), Theano or CNTK (Microsoft)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Load the tarin and test subsets of the 20 Newsgroups data set from sklearn datasets. Remove the headers, footers and qoutes from the news article when loading data sets. Use 45 for random_state. In order to get faster execution times for this practical we will work on a partial dataset with only 5 categories out of the 20 available in the dataset ('rec.sport.hockey', 'talk.politics.mideast', 'soc.religion.christian', 'comp.graphics', 'sci.med').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['rec.sport.hockey', 'talk.politics.mideast', 'soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'), \n",
    "                                  categories=categories, shuffle=True, random_state=321)\n",
    "# type(twenty_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'), \n",
    "                                 categories=categories, shuffle=True, random_state=321)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **Find out about the number of news articles in train and test sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_train.filenames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_test.filenames.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **Covert the train and test data sets to separate dataframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\nDr. cheghadr bA namakand!  They just wait un...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n\\n\\n\\n:) No...I was one of the lucky ones....</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n[After a small refresh Hasan got on the tr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Before getting excited and implying that I am ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have posted disp135.zip to alt.binaries.pict...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  \\nDr. cheghadr bA namakand!  They just wait un...      4\n",
       "1  \\n\\n\\n\\n\\n:) No...I was one of the lucky ones....      2\n",
       "2  \\n\\n[After a small refresh Hasan got on the tr...      4\n",
       "3  Before getting excited and implying that I am ...      4\n",
       "4  I have posted disp135.zip to alt.binaries.pict...      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_train = pd.DataFrame(list(zip(twenty_train.data, twenty_train.target)), columns=['text', 'label'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi all, Ive applied for the class of 93 at qui...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:In article &lt;enea1-270493135255@enea.apple.com...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\nI don't know the answer the to this one, alt...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nWe here at IBM have the same problem with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\nI was at an Adobe seminar/conference/propaga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  hi all, Ive applied for the class of 93 at qui...      2\n",
       "1  :In article <enea1-270493135255@enea.apple.com...      2\n",
       "2  \\nI don't know the answer the to this one, alt...      0\n",
       "3  \\n\\nWe here at IBM have the same problem with ...      0\n",
       "4  \\nI was at an Adobe seminar/conference/propaga...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame(list(zip(twenty_test.data, twenty_test.target)), columns=['text', 'label'])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(binary=True)\n",
    "\n",
    "def tfidf_features(txt, flag):\n",
    "    if flag == \"train\":\n",
    "        x = tfidf.fit_transform(txt)\n",
    "    else:\n",
    "        x = tfidf.transform(txt)\n",
    "    x = x.astype('float16')\n",
    "    return x \n",
    "\n",
    "X_train = tfidf_features(df_train.text.values, flag=\"train\")\n",
    "X_test = tfidf_features(df_test.text.values, flag=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the list of strings to the matrix of vectors (to be fed our nn)\n",
    "\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(df_train.label.values)\n",
    "y_train = keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2941, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = lb.transform(df_test.label.values)\n",
    "y_test = keras.utils.to_categorical(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **In order to feed predictive deep learning models with the text data, one first need to turn the text into vectors of numerical values suitable for statistical analysis. Use the CountVectorizer and create a document-term matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train = count_vect.fit_transform(df_train.text.values)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.nnz / float(X_train.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = count_vect.transform(df_test.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extracted vectors are very sparse, with an average of 111 non-zero components by sample in a more than 37000-dimensional space (less than 0.3% non-zero features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **Now we want to visualize the output of KMeans clustering. To do this, first use PCA to transform the high-dimensional feature space into 2 dimensions, and plot the points using a scatter plot.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                371490    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 55        \n",
      "=================================================================\n",
      "Total params: 371,545\n",
      "Trainable params: 371,545\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2447 - accuracy: 0.9660\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2353 - accuracy: 0.9680\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2262 - accuracy: 0.9691\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.2172 - accuracy: 0.9697\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.2086 - accuracy: 0.9701\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - ETA: 0s - loss: 0.1989 - accuracy: 0.97 - 0s 5ms/step - loss: 0.2001 - accuracy: 0.9701\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1919 - accuracy: 0.9708\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.9711\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1764 - accuracy: 0.9711\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1691 - accuracy: 0.9718\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1621 - accuracy: 0.9725\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1554 - accuracy: 0.9725\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.9725\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1428 - accuracy: 0.9735\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9738\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1314 - accuracy: 0.9738\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1261 - accuracy: 0.9748\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9755\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1163 - accuracy: 0.9755\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 0.1118 - accuracy: 0.9755\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=20, batch_size=512)\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 800us/step - loss: 0.2111 - accuracy: 0.8912\n",
      "Test set\n",
      "  Loss: 0.211\n",
      "  Accuracy: 0.891\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2941,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. **Evaluate the quality of the 5Means clustering with the sklearn metrics for clustering: homogeneity_score, completeness_score, v_measure_score, adjusted_rand_score, silhouette_score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. **Apply the steps in questions 4 and 5, by choosing 2 and 10 as the number of clusters. Compare the visualisations. (with a plot?) Apply the Elbow method to find the optimal k.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. **Manually create a dataframe with two news articles x and z, and predict cluster labels for new dataset with the optimal KMeans.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. **Hierarchical clustering is a type of unsupervised machine learning algorithm used to cluster unlabeled data points. Like K-means clustering, hierarchical clustering also groups together the data points with similar characteristics. Apply the Hierarchical Clustering with ward linkage.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11\\. **Plot the dendrogram of the hierarchical clustering.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12\\. **Train a Negative Matrix Factorization model for topic modeling on a tf document-term matrix of the BBCSport dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13\\. **Show top 10 words per topic with their probabilities.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14\\. **Use the NMF model and identify the topic of a new text: \"Robben open to playing at Euro 2020 with Netherlands after bagging two assists for Groningen\"? Simply call the transform function of the model and it will give you a score of each topic. Choose the topic with the highest score to determine it’s topic.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15\\. ****Train a Latent Dirichlet Allocation model for topic modeling and repeat the steps in 12, 13 and 14.****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16\\. **Compare the performance of the LDA model versus the NMF model.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
