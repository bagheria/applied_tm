{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 3: Feature Selection & Dimension Reduction\n",
    "#### Ayoub Bagheri\n",
    "<img src=\"img/uu_logo.png\" alt=\"logo\" align=\"right\" title=\"UU\" width=\"50\" height=\"20\" />\n",
    "\n",
    "#### Applied Text Mining - Utrecht Summer School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical, we are going to learn about feature selection and dimension reduction methods for text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will use the following libraries. Take care to have them installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. **Here we are going to use a news article data set, originating from BBC news website. This dataset provided for use as benchmarks for machine learning research. The BBC data set consists of 2225 documents and 5 categories: business, entertainment, politics, sport, and tech. Load the dataset and convert it to a dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chris Evans back on the market\\n\\nBroadcaster ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Giggs handed Wales leading role\\n\\nRyan Giggs ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wales silent on Grand Slam talk\\n\\nRhys Willia...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya lift Chepkemei's suspension\\n\\nKenya's a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lee to create new film superhero\\n\\nComic book...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Chris Evans back on the market\\n\\nBroadcaster ...      1\n",
       "1  Giggs handed Wales leading role\\n\\nRyan Giggs ...      3\n",
       "2  Wales silent on Grand Slam talk\\n\\nRhys Willia...      3\n",
       "3  Kenya lift Chepkemei's suspension\\n\\nKenya's a...      3\n",
       "4  Lee to create new film superhero\\n\\nComic book...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for reproducibility\n",
    "random_state = 321 \n",
    "\n",
    "DATA_DIR = \"data/bbc\"\n",
    "data = load_files(DATA_DIR, encoding=\"utf-8\", decode_error=\"replace\", random_state=random_state)\n",
    "df = pd.DataFrame(list(zip(data['data'], data['target'])), columns=['text', 'label'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. **Print the unique target names in your data and check the number of articles in each category. Then split your data into training (80%) and test (20%) sets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels, counts = np.unique(df['label'], return_counts=True) # np.unique(data.target, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'business': 510, 'entertainment': 386, 'politics': 417, 'sport': 511, 'tech': 401}\n"
     ]
    }
   ],
   "source": [
    "print(dict(zip(data.target_names, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. **Use the CountVectorizer from sklearn and convert the text data into a document-term matrix. What is the difference between CountVectorizer and tfidfVectorizer(use_idf=False)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1780, 25223)\n"
     ]
    }
   ],
   "source": [
    "#tokenizer to remove unwanted elements from out data like symbols\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's bag of words tool.\n",
    "# If you have memory issues, reduce the max_features value so you can continue with the practical\n",
    "vectorizer = CountVectorizer(lowercase=True,\n",
    "                             tokenizer=token.tokenize,\n",
    "                             stop_words='english',\n",
    "                             ngram_range=(1, 2),\n",
    "                             analyzer='word',\n",
    "                             min_df=3,\n",
    "                             max_features=None)\n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model and learns the vocabulary; \n",
    "# second, it transforms our data into feature vectors. \n",
    "# The input to fit_transform should be a list of strings.\n",
    "bbc_dtm = vectorizer.fit_transform(X_train)\n",
    "print(bbc_dtm.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference is that the TfidfVectorizer() returns floats while the CountVectorizer() returns ints. And that’s to be expected – as explained in the documentation quoted above, TfidfVectorizer() assigns a score while CountVectorizer() counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. **Print top 20 frequent words in the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s', 'said', 'mr', 'year', 'people', 'new', 't', 'time', 'world',\n",
       "       'government', 'uk', 'years', 'best', 'just', 'told', 'film',\n",
       "       'make', '1', 'game', 'like'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = np.argsort(np.asarray(bbc_dtm.sum(axis=0)).ravel())[::-1]\n",
    "feature_names = np.array(vectorizer.get_feature_names_out())\n",
    "feature_names[importance[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter-based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. **From the feature selection library in sklearn load the SelectKBest function and apply it on the BBC dataset using the chi-squared method. Extract top 20 features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1780x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 4428 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch2 = SelectKBest(chi2, k=20)\n",
    "ch2.fit_transform(bbc_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_chi = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " 'blair',\n",
       " 'brown',\n",
       " 'computer',\n",
       " 'digital',\n",
       " 'election',\n",
       " 'film',\n",
       " 'government',\n",
       " 'labour',\n",
       " 'minister',\n",
       " 'mobile',\n",
       " 'mr',\n",
       " 'mr blair',\n",
       " 'music',\n",
       " 'net',\n",
       " 'party',\n",
       " 'people',\n",
       " 'software',\n",
       " 'technology',\n",
       " 'users']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. **Repeat the analysis in question 5 with the mutual information feature selection method. Do you get the same list of words as compared to the chi-squared method?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1780x20 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6350 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_info = SelectKBest(mutual_info_classif, k=20)\n",
    "mutual_info.fit_transform(bbc_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blair',\n",
       " 'coach',\n",
       " 'election',\n",
       " 'film',\n",
       " 'firm',\n",
       " 'game',\n",
       " 'government',\n",
       " 'labour',\n",
       " 'market',\n",
       " 'minister',\n",
       " 'mr',\n",
       " 'music',\n",
       " 'party',\n",
       " 'people',\n",
       " 'said',\n",
       " 'secretary',\n",
       " 'technology',\n",
       " 'tory',\n",
       " 'users',\n",
       " 'win']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_mutual_info = [feature_names[i] for i\n",
    "                         in mutual_info.get_support(indices=True)]\n",
    "feature_names_mutual_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can build a classifier and train it using the output of these feature selection techniques. We are not going to do this right now, but if you are interested you can transform your training and test set using the selected features and continue with your classifier! Here are some tips:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = mutual_info.fit_transform(bbc_dtm, y_train)\n",
    "# X_test = mutual_info.transform(X_test_vectorized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. **One of the functions for embedded feature selection is the SelectFromModel function in sklearn. Use this function with L1 norm SVM and check how many non-zero coefficients left in the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the matrix before applying the embedded feature selection: (1780, 25223)\n",
      "shape of the matrix before applying the embedded feature selection: (1780, 154)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape of the matrix before applying the embedded feature selection:\", bbc_dtm.shape)\n",
    "\n",
    "lsvc = LinearSVC(C=0.01, penalty=\"l1\", dual=False)\n",
    "model = SelectFromModel(lsvc).fit(bbc_dtm, y_train) # you can add threshold=0.18 as another argument to select features that have an importance of more than 0.18\n",
    "X_new = model.transform(bbc_dtm)\n",
    "print(\"shape of the matrix before applying the embedded feature selection:\", X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectFromModel(estimator=LinearSVC(C=0.01, dual=False, penalty='l1'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also check the coefficient values\n",
    "model.estimator_.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8\\. **What are the top features according to the SVM model? Tip: Use the function model.get_support() to find these features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, ..., False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features selected by SelectFromModel:  ['000' '1' '2' '2004' '6' 'airlines' 'album' 'analysts' 'apple' 'athens'\n",
      " 'athletics' 'award' 'ballet' 'ban' 'band' 'bank' 'bbc' 'best' 'bid'\n",
      " 'blair' 'blog' 'book' 'britain' 'broadband' 'brown' 'business' 'champion'\n",
      " 'chart' 'chelsea' 'chief' 'children' 'china' 'club' 'coach' 'comedy'\n",
      " 'companies' 'company' 'computer' 'conte' 'content' 'council' 'cup' 'data'\n",
      " 'deal' 'digital' 'dollar' 'doping' 'drugs' 'e' 'economic' 'economy'\n",
      " 'education' 'election' 'england' 'eu' 'european' 'euros' 'film'\n",
      " 'financial' 'firm' 'firms' 'fraud' 'game' 'games' 'gaming' 'glazer'\n",
      " 'good' 'government' 'group' 'growth' 'high' 'home' 'howard' 'iaaf'\n",
      " 'information' 'injury' 'just' 'labour' 'league' 'like' 'liverpool' 'lord'\n",
      " 'm' 'make' 'market' 'match' 'microsoft' 'million' 'minister' 'mobile'\n",
      " 'mps' 'mr' 'music' 'musical' 'net' 'new' 'nintendo' 'number' 'o' 'oil'\n",
      " 'old' 'olympic' 'online' 'party' 'people' 'plans' 'play' 'players'\n",
      " 'police' 'president' 'prices' 'public' 'rights' 'rugby' 's' 'said'\n",
      " 'sales' 'says' 'season' 'secretary' 'series' 'service' 'services' 'set'\n",
      " 'shares' 'singer' 'site' 'software' 'sony' 'spam' 'star' 'stars' 'state'\n",
      " 't' 'team' 'technology' 'time' 'trade' 'tv' 'uk' 'united' 'use' 'used'\n",
      " 'users' 'using' 'video' 'virus' 'web' 'website' 'win' 'won' 'world'\n",
      " 'year' 'year old']\n"
     ]
    }
   ],
   "source": [
    "print(\"Features selected by SelectFromModel: \", feature_names[model.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. **Create a pipeline with the tfidf representation and a random forest classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. **Fit the pipeline on the training set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('feature_extraction', TfidfTransformer()),\n",
       "                ('classification', RandomForestClassifier())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11\\. **Use the pipeline to predict the outcome variable on your test set. Evaluate the performance of the pipeline using the classification_report function on the test subset. How do you analyze your results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.87      0.96      0.91        92\n",
      "entertainment       0.99      0.89      0.94        84\n",
      "     politics       0.96      0.91      0.93        77\n",
      "        sport       0.97      1.00      0.99       111\n",
      "         tech       0.98      0.98      0.98        81\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.95      0.95       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = clf1.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred1, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12\\. **Create your second pipeline with the tfidf representation and a random forest classifier with the addition of an embedded feature selection using the SVM classification method with L1 penalty. Fit the pipeline on your training set and test it with the test set. How does the performance change?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('feature_extraction', TfidfTransformer()),\n",
       "                ('feature_selection',\n",
       "                 SelectFromModel(estimator=LinearSVC(dual=False,\n",
       "                                                     penalty='l1'))),\n",
       "                ('classification', RandomForestClassifier())])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = clf2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.92      0.93      0.93        92\n",
      "entertainment       0.99      0.93      0.96        84\n",
      "     politics       0.91      0.91      0.91        77\n",
      "        sport       0.98      0.97      0.98       111\n",
      "         tech       0.93      0.99      0.96        81\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.95      0.95       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred2, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13\\. **Create your third and forth pipelines with the tfidf representation, a chi2 feature selection (with 20 and 200 features for clf3 and clf4, respectively), and a random forest classifier.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectKBest(chi2, k=20)),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('feature_extraction', TfidfTransformer()),\n",
       "                ('feature_selection',\n",
       "                 SelectKBest(k=20,\n",
       "                             score_func=<function chi2 at 0x0000017DCE3A8B80>)),\n",
       "                ('classification', RandomForestClassifier())])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.64      0.45      0.53        92\n",
      "entertainment       0.81      0.56      0.66        84\n",
      "     politics       0.77      0.73      0.75        77\n",
      "        sport       0.63      0.99      0.77       111\n",
      "         tech       0.87      0.80      0.83        81\n",
      "\n",
      "     accuracy                           0.72       445\n",
      "    macro avg       0.74      0.71      0.71       445\n",
      " weighted avg       0.73      0.72      0.71       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred3 = clf3.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred3, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectKBest(chi2, k=200)),\n",
    "    ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('feature_extraction', TfidfTransformer()),\n",
       "                ('feature_selection',\n",
       "                 SelectKBest(k=200,\n",
       "                             score_func=<function chi2 at 0x0000017DCE3A8B80>)),\n",
       "                ('classification', RandomForestClassifier())])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.85      0.91      0.88        92\n",
      "entertainment       0.97      0.93      0.95        84\n",
      "     politics       0.90      0.86      0.88        77\n",
      "        sport       0.99      0.97      0.98       111\n",
      "         tech       0.94      0.98      0.96        81\n",
      "\n",
      "     accuracy                           0.93       445\n",
      "    macro avg       0.93      0.93      0.93       445\n",
      " weighted avg       0.93      0.93      0.93       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred4 = clf4.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred4, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14\\. **We can change the learner by simply plugging a different classifier object into our pipeline. Create your fifth pipeline with L1 norm SVM for the feature selection method and naive Bayes for the classifier. Compare your results on the test set with the previous pipelines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
    "    ('classification', MultinomialNB(alpha=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('feature_extraction', TfidfTransformer()),\n",
       "                ('feature_selection',\n",
       "                 SelectFromModel(estimator=LinearSVC(dual=False,\n",
       "                                                     penalty='l1'))),\n",
       "                ('classification', MultinomialNB(alpha=0.01))])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.93      0.95        92\n",
      "entertainment       1.00      0.94      0.97        84\n",
      "     politics       0.95      0.99      0.97        77\n",
      "        sport       1.00      1.00      1.00       111\n",
      "         tech       0.93      0.98      0.95        81\n",
      "\n",
      "     accuracy                           0.97       445\n",
      "    macro avg       0.97      0.97      0.97       445\n",
      " weighted avg       0.97      0.97      0.97       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred5 = clf5.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred5, target_names=data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: Dimension reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15\\. **Dimensionality reduction methods such as PCA and SVD can be used to project the data into a lower dimensional space. If you run PCA with your text data, you might end up with the message \"PCA does not support sparse input. See TruncatedSVD for a possible alternative.\" Therefore, we will use the Truncated SVD function from the sklearn package and we want to find out how much of the variance in the BBC data set is explained with different components. For this, first create a tfidf matrix and use that to make a co-occurrence matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the TFIDF vectorizer: (1780, 26739)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "X = tfidf_vect.fit_transform(X_train)\n",
    "Xc = (X.T * X) # this is co-occurrence matrix in sparse csr format\n",
    "Xc.setdiag(0) # sometimes you want to fill same word cooccurence to 0\n",
    "print(\"Shape of the TFIDF vectorizer:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.00024418 0.         ... 0.         0.         0.        ]\n",
      " [0.00024418 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Xc.todense()) # print out matrix in dense format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16\\. **Run the SVD function with different values for components: 1, 2, 4, 5, 10, 15, 20, 50, 100. Plot the explained variance ratio for each component of Truncated SVD.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components = 1 and explained variance = 0.8302335701200985\n",
      "Number of components = 2 and explained variance = 0.9165093632208284\n",
      "Number of components = 4 and explained variance = 0.9291569440571864\n",
      "Number of components = 5 and explained variance = 0.9344860553539854\n",
      "Number of components = 10 and explained variance = 0.9477460365510291\n",
      "Number of components = 15 and explained variance = 0.9529731073724195\n",
      "Number of components = 20 and explained variance = 0.9560375991471993\n",
      "Number of components = 50 and explained variance = 0.9645814066708002\n",
      "Number of components = 100 and explained variance = 0.9711191624492502\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_comp = [1, 2, 4, 5, 10, 15, 20, 50, 100] # list containing different values of components\n",
    "explained = [] # explained variance ratio for each component of Truncated SVD\n",
    "for x in n_comp:\n",
    "    svd = TruncatedSVD(n_components=x, random_state=321)\n",
    "    svd.fit(Xc)\n",
    "    explained.append(svd.explained_variance_ratio_.sum())\n",
    "    print(\"Number of components = %r and explained variance = %r\"%(x,svd.explained_variance_ratio_.sum()))\n",
    "\n",
    "plt.plot(n_comp, explained)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"Plot of Number of components v/s explained variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17\\. **How many components are needed to explain at least 95% of the variance?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the selected values, it seems 15 components are needed to explain 95% of the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "18\\. **Use these components and train a SVM model on the BBC dataset. Make a pipeline for your model. Compare your results on the test set with the previous pipelines.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('feature_extraction', TfidfTransformer()),\n",
    "    ('feature_selection', TruncatedSVD(n_components=15, random_state=321)),\n",
    "    ('classification', LinearSVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('feature_extraction', TfidfTransformer()),\n",
       "                ('feature_selection',\n",
       "                 TruncatedSVD(n_components=15, random_state=321)),\n",
       "                ('classification', LinearSVC())])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.91      0.92      0.92        92\n",
      "entertainment       1.00      0.94      0.97        84\n",
      "     politics       0.91      0.92      0.92        77\n",
      "        sport       0.99      1.00      1.00       111\n",
      "         tech       0.94      0.96      0.95        81\n",
      "\n",
      "     accuracy                           0.95       445\n",
      "    macro avg       0.95      0.95      0.95       445\n",
      " weighted avg       0.95      0.95      0.95       445\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred6 = clf6.predict(X_test)\n",
    "print(metrics.classification_report(y_test, y_pred6, target_names=data.target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
