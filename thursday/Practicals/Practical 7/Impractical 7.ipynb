{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfJhz1-CiB9k"
   },
   "source": [
    "# Practical 7: RNN vs CNN\n",
    "#### Ayoub Bagheri\n",
    "<img src=\"img/uu_logo.png\" alt=\"logo\" align=\"right\" title=\"UU\" width=\"50\" height=\"20\" />\n",
    "\n",
    "#### Applied Text Mining - Utrecht Summer School"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_ACYwqliB9p"
   },
   "source": [
    "In this practical, we will try RNN and CNN deep learning architectures. We will work with the famous 20 Newsgroups dataset from the sklearn library to apply deep learning models using the Keras package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OK2Ne1RPiB9s"
   },
   "source": [
    "Today we will use the following libraries. Take care to have them installed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUNtlL0miB9u"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.utils import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras import layers, utils\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6v8QDnWRiB9y"
   },
   "source": [
    "First run the following lines to make your data ready for the models (we used this code in the previous practical):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOMWysYsiB90"
   },
   "outputs": [],
   "source": [
    "# select couple of the categories in 20newsgroups\n",
    "categories = ['rec.sport.hockey', 'talk.politics.mideast', 'soc.religion.christian', 'comp.graphics', 'sci.med']\n",
    "# fetch the training set\n",
    "twenty_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'),\n",
    "                                  categories=categories, shuffle=True, random_state=321)\n",
    "# fetch the test set\n",
    "twenty_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'),\n",
    "                                 categories=categories, shuffle=True, random_state=321)\n",
    "# convert to a dataframe\n",
    "df_train = pd.DataFrame(list(zip(twenty_train.data, twenty_train.target)), columns=['text', 'label'])\n",
    "df_test = pd.DataFrame(list(zip(twenty_test.data, twenty_test.target)), columns=['text', 'label'])\n",
    "# tokenizer from keras\n",
    "tokenizer = Tokenizer(num_words=20000)\n",
    "tokenizer.fit_on_texts(df_train.text.values)\n",
    "X_train = tokenizer.texts_to_sequences(df_train.text.values)\n",
    "X_test = tokenizer.texts_to_sequences(df_test.text.values)\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index for sequence padding\n",
    "# pad sequence\n",
    "maxlen = 100\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
    "# Encode the list of newsgroups into categorical integer values\n",
    "lb = LabelEncoder()\n",
    "y = lb.fit_transform(df_train.label.values)\n",
    "y_train = utils.np_utils.to_categorical(y)\n",
    "y = lb.transform(df_test.label.values)\n",
    "y_test = utils.np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1zAvWEeiB94"
   },
   "source": [
    "And here the code to a function for plotting the history of training for our neural network model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTVBbYjhiB95"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "def plot_history(history, val=0):\n",
    "    acc = history.history['accuracy']\n",
    "    if val == 1:\n",
    "        val_acc = history.history['val_accuracy'] # we can add a validation set in our fit function with nn\n",
    "    loss = history.history['loss']\n",
    "    if val == 1:\n",
    "        val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    if val == 1:\n",
    "        plt.plot(x, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    if val == 1:\n",
    "        plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxNRwjAXiB-A"
   },
   "source": [
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4PaaEIpiB-D"
   },
   "source": [
    "### Recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRI3mii0iB-E"
   },
   "source": [
    "A recurrent neural network (RNN) is a natural generalization of feed-forward neural networks to sequence data such as text. In contrast to a feed-forward neural network, however, it accepts a new input at every time step (layer). Long-short term memory (LSTM) networks are a variant of RNNs. The LSTM introduces mechanisms to decide what should be remembered and what should be forgotten in learning from text documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "phil2VqYiB-G"
   },
   "source": [
    "1\\. **Build a neural network model with an LSTM layer of 100 units. As before, the first layer should be an embedding layer, then the LSTM layer, a Dense layer, and the output Dense layer for the 5 news categories. Compile the model and print its summary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ey6GJQqliB-J"
   },
   "source": [
    "The first layer is the Embedded layer that uses 100 length vectors to represent each word. The next layer is the LSTM layer with 100 memory units (smart neurons!). Finally, because this is a classification problem we use a Dense output layer with 5 neurons and a softmax activation function to make 0 or 1 predictions for the five classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M4AxX83KiB-K"
   },
   "source": [
    "2\\.**Fit the model in 5 epochs.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LV_PusqZiB-N"
   },
   "source": [
    "3\\.**Evaluate the accuracy of training and test data using your model and plot the history of fit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PntM4r0FiB-d"
   },
   "source": [
    "### Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_JgNsNFkiB-f"
   },
   "source": [
    "Convolutional neural networks or also called convnets are one of the most exciting developments in machine learning in recent years. They have revolutionized image classification and computer vision by being able to extract features from images and using them in neural networks. The properties that made them useful in image processing makes them also handy for sequence processing. When you are working with sequential data, like text, you work with one dimensional convolutions, but the idea and the application stays the same.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHJlq04ciB-g"
   },
   "source": [
    "4\\. **Build a neural network model with an convolution layer (Conv1D) of 128 units and window size of 5. As before, the first layer should be an embedding layer, then the CNN layers, a Dense layer, and the output Dense layer for the 5 news categories. Do you also need a pooling layer? Compile the model and print its summary.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWAQoJxmiB-k"
   },
   "source": [
    "5\\. **Fit the model in 5 epochs, and evaluate the accuracy of the training and test data using your model. Plot the history of the fit.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "csKy_Pn_iB-n"
   },
   "source": [
    "6\\. **How do you compare the performance of the two models also with regard to 5 and 20 iterations?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scQBmwA4iB-p"
   },
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOM2A29MiB-p"
   },
   "source": [
    "One crucial steps of deep learning and working with neural networks is hyperparameter optimization. Hyperparameters are parameters that are chosen by the algorithm designer. Tuning them is very important!\n",
    "One popular method for hyperparameter optimization is grid search. What this method does is it takes lists of parameters and it runs the model with each parameter combination that it can find. It is the most thorough way but also the most computationally heavy way to do this. Another common way, random search, which youâ€™ll see in action here, simply takes random combinations of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfR5Aw-4iB-r"
   },
   "source": [
    "7\\. **Write function for creating your cnn-based model which has the number of filters, kernel size, and embedding size as input arguments. Name your function `create_model`. For the rest follow the architecture of your previous cnn model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZyg3lp6iB-u"
   },
   "source": [
    "8\\. **Dictionary in Python is an ordered collection of data values. Use the dict structure to define your hyperparameters for the cnn model. You can include the number of filters, kernel size, and embedding size.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTWvvtgliB-w"
   },
   "source": [
    "When constructing this structure you must provide a dictionary of hyperparameters to evaluate in the param_grid argument. This is a map of the model parameter name and an array of values to try."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vK_ldjGpiB-x"
   },
   "source": [
    "9\\. **Use the `KerasClassifier` from `scikeras` to create your model with the `create_model` function, 15 epochs, and `batch_size` of 64.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRQsGxjJiB-z"
   },
   "source": [
    "10\\. **Time to call the `RandomizedSearchCV` function. Use your model, your selected grid for hyperparameters, and 5-fold cross-validation.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bjEtvjO5iB-0"
   },
   "source": [
    "As you see in this function, there are more input arguments which you can set including `n_jobs` and `n_iter`. By default, the random search (or grid search) will only use one thread. By setting the `n_jobs` argument in the `RandomizedSearchCV` (or `GridSearchCV`) constructor to -1, the process will use all cores on your machine.\n",
    "It is also worth mentioning that by default, accuracy is the score that is optimized, but other scores can be specified in the `score` argument of the `GridSearchCV` constructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-qnhfuuiB-1"
   },
   "source": [
    "11\\. **Fit your grid on `X_train` and `y_train`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccBQAfXIiB-3"
   },
   "source": [
    "12\\. **Find the best scores and the best values for the hyperparameters.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hj_tbu-PiB-5"
   },
   "source": [
    "The `best_score_` attribute provides access to the best score observed during the optimization procedure and the `best_params_` attribute shows the combination of parameters that achieved the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JB3HFBjXiB-5"
   },
   "source": [
    "13\\. **Evaluate the performance on the test set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcUZEKeCiB-7"
   },
   "source": [
    "**Now you can use the best hyperparameter values to build your final model. Do that as your fun homework!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
